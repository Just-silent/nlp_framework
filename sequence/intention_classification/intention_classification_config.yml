# shared for multiple projects in this machine, raw data, read only

home:
  dir: 'D://workspace'
#  dir: '//home//admin//jupyter//workspace'

device: 'cpu'
#device: 'cuda:0'

# Shared for multiple modules in the project
project:
  name: 'email'
  dir:
    work: '{home.dir}//{project.name}'
  seed: 19980603

pretrained_models:
  name: 'bert_base_chinese'
  dir: '{home.dir}//common//pretrained_models//{pretrained_models.name}'
  full_finetuning: True
  is_use: False

data:
  name: 'email'
  base_dir: '{home.dir}//data'
  ori_path: '{data.base_dir}//{data.name}//classification.xlsx'
  train_path: '{data.base_dir}//{data.name}//classification_train.xlsx'
  valid_path: '{data.base_dir}//{data.name}//classification_valid.xlsx'
  test_path: '{data.base_dir}//{data.name}//classification_valid.xlsx'

  vocab_path: '{pretrained_models.dir}//vocab.txt'

  max_len: 150

  shuffle: True

  token_pad_idx: 0
  tag_pad_idx: 0

  num_vocab: 20000
  num_tag: 8
  batch_size: 4
  batch_first: True

  train_shuffle: True

  test_shuffle: False

# specified for specific module
model:
  name: 'email_model'
  dim_embedding: 300
  dim_hidden: 768
  num_layer: 1
  bidirectional: True
  batch_first: False
  nlayer: 1
  lr: 1.0e-4
  hidden_dropout_prob: 0.5
  is_pretrained_model: True
  label_pad: False
  is_crf: False

loss:
  alpha: 1.0
  beta: 1.0e-3

evaluation:
  kind: seq
  type: micro # macro
  is_display: True

learn:
  dropout_rate: 0.1
  learning_rate: 5.0e-5
  momentum: 0.9
  weight_decay: 1.0e-2
  batch_display: 20
  episode: 20
  dir:
    work: "{project.dir.work}////{model.name}"
    log: '{learn.dir.work}//log'
    data: "{learn.dir.work}//data"
    saved: '{learn.dir.work}//saved'
    result: '{learn.dir.work}//result//result.xlsx'
    summary: '{learn.dir.work}//summary'